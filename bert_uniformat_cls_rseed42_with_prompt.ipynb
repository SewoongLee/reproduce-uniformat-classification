{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduction of the UniformatBridge model implementation\n",
    "\n",
    "- This is an **_unofficial_** reproduction of the experiment described in \"Transformer language model for mapping construction schedule activities to uniformat categories\" by Yoonhwa Jung, Julia Hockenmaier, and Mani Golparvar-Fard, 2024.\n",
    "- The study can be accessed at https://doi.org/10.1016/j.autcon.2023.105183."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.6\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6p: \"Five epochs with a batch size of 32, a dropout rate of 0.1, and a learning rate of 1.5eâˆ’5 were used to fine-tune the model.\"\n",
    "epoch_size = 1#5\n",
    "batch_size = 32\n",
    "dropout_rate = 0.1  # BertForSequenceClassification default dropout_rate = 0.1\n",
    "learning_rate = 1.5e-5\n",
    "\n",
    "rseed = 42  # 7p: \"In Table 2 and 3, ðœ‡ is the average performance on three random seeds, and ðœŽ is their standard deviation.\"\n",
    "dataset_path = \"E:/_datasets/jung_et_al_2024/\"  # Data should not be shared publicly.\n",
    "experiment_name = 'with_prompt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BIM and ASTM Uniformat categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(dataset_path+\"0-overall-level3.xlsx\", header=0)\n",
    "\n",
    "cls = 'Level3'\n",
    "df = df.loc[:, ['predwbs2', 'predwbs', 'predtask', 'wbs2', 'wbs', 'name', 'sucwbs2', 'sucwbs', 'suctask', cls]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CONSTRUCTION SUPERSTRUCTURE > Roof > Set Mechanical Equipment [pred] CONSTRUCTION SUPERSTRUCTURE > Roof > Pipe Mechanical Equipment [succ]  100 KINGSHIGHWAY > COMMISSIONNG & INSPECTIONS > STARTUP',\n",
       " 'D2040')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokens = ['[pred]', '[succ]']\n",
    "\n",
    "df['text'] = df.apply(\n",
    "    lambda row: f\"{row['predwbs2']} > {row['predwbs']} > {row['predtask']} [pred] {row['wbs2']} > {row['wbs']} > {row['name']} [succ] {row['sucwbs2']} > {row['sucwbs']} > {row['suctask']}\",\n",
    "    axis=1\n",
    ")\n",
    "df['label'] = df[cls]\n",
    "\n",
    "print_idx = 6538  # D2040: 'Rain Water Drainage' case in Table 4\n",
    "df['text'][print_idx], df['label'][print_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20469, 6823, 6824)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "texts = df['text']\n",
    "labels = df['label']\n",
    "\n",
    "# 6p: \"This dataset is further split into training, validation, and testing using a 60-20-20 distribution.\"\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(texts, labels, test_size=0.4, random_state=rseed)\n",
    "validation_texts, test_texts, validation_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=rseed)\n",
    "\n",
    "(len(train_texts), len(validation_texts), len(test_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # Move to device\n",
    "# train_labels_encoded = torch.tensor(encoded_labels[train_texts.index], dtype=torch.long).to(device)\n",
    "# validation_labels_encoded = torch.tensor(encoded_labels[validation_texts.index], dtype=torch.long).to(device)\n",
    "# test_labels_encoded = torch.tensor(encoded_labels[test_texts.index], dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(set(encoded_labels))).to(device)\n",
    "\n",
    "tokenizer.add_tokens(new_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "tokenizer, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize a sequence of schedule activities (Texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2810, 28391,  1028,  4412,  1028,  2275,  6228,  3941, 30522,\n",
       "          2810, 28391,  1028,  4412,  1028,  8667,  6228,  3941, 30523,  2531,\n",
       "          5465,  4048,  5603,  4576,  1028,  3222,  3070,  1004, 29589,  1028,\n",
       "         22752,   102]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode(texts):\n",
    "    return tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "\n",
    "encode(df['text'][print_idx])['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20469, 148]) torch.Size([20469, 148]) torch.Size([20469])\n",
      "torch.Size([6823, 147]) torch.Size([6823, 147]) torch.Size([6823])\n",
      "torch.Size([6824, 150]) torch.Size([6824, 150]) torch.Size([6824])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def make_dataloader(plain_texts, encoded_labels, batch_size=32):\n",
    "    '''\n",
    "    plain_texts: list of strings (should be encoded when making dataloader due to tokenizer padding/truncation)\n",
    "    encoded_labels: list of class indices (should be encoded beforehand using LabelEncoder with the entire dataset)\n",
    "    '''\n",
    "    texts = encode(plain_texts).to(device)\n",
    "    labels = torch.tensor(encoded_labels, dtype=torch.long).to(device)\n",
    "    dataset = TensorDataset(\n",
    "        texts['input_ids'], \n",
    "        texts['attention_mask'], \n",
    "        labels,\n",
    "    )\n",
    "    return DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "train_labels_encoded = encoded_labels[train_texts.index]\n",
    "validation_labels_encoded = encoded_labels[validation_texts.index]\n",
    "test_labels_encoded = encoded_labels[test_texts.index]\n",
    "\n",
    "train_loader = make_dataloader(train_texts.tolist(), train_labels_encoded, batch_size)\n",
    "validation_loader = make_dataloader(validation_texts.tolist(), validation_labels_encoded, batch_size)\n",
    "test_loader = make_dataloader(test_texts.tolist(), test_labels_encoded, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Move to device\n",
    "# train_encodings = encode(train_texts.tolist()).to(device)\n",
    "# validation_encodings = encode(validation_texts.tolist()).to(device)\n",
    "# test_encodings = encode(test_texts.tolist()).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make DataLoader (Texts & Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import TensorDataset\n",
    "\n",
    "# # attention_mask is 1 for real tokens and 0 for padding tokens\n",
    "# train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels_encoded)\n",
    "# validation_dataset = TensorDataset(validation_encodings['input_ids'], validation_encodings['attention_mask'], validation_labels_encoded)\n",
    "# test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], test_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### â˜… Additional Datasets: ASTM Uniformat II Classification for Building Elements Description\n",
    "- https://www.govinfo.gov/content/pkg/GOVPUB-C13-5af96252bc88826c911daac93c449927/pdf/GOVPUB-C13-5af96252bc88826c911daac93c449927.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Publicly available definition of ASTM Uniformat II + CoT Prompt\n",
    "# df_astm = pd.read_csv(\"public_astm_uniformat_ii_classification.csv\", header=0)\n",
    "\n",
    "# astm_labels = df_astm.apply(\n",
    "#     lambda row: f\"[{row['Class']}]\",\n",
    "#     axis=1\n",
    "# )\n",
    "# df_astm = df_astm[astm_labels.isin(label_encoder.classes_)] # Use only the classes that are in the dataset\n",
    "# df_astm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### â˜… Additional Datasets: Data augmentation with GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "# gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# def generate_with_gpt2(prompt_text, max_len=100, repetition_penalty=1.2):\n",
    "#     inputs = gpt2_tokenizer.encode(prompt_text, return_tensors='pt')\n",
    "#     outputs = gpt2_model.generate(\n",
    "#         inputs, \n",
    "#         pad_token_id=gpt2_tokenizer.eos_token_id, \n",
    "#         max_length=max_len, \n",
    "#         # do_sample=True, temperature=0.9, # Probabilistic\n",
    "#         repetition_penalty=repetition_penalty # Deterministic\n",
    "#     )\n",
    "#     generated_text = gpt2_tokenizer.decode(outputs[0])\n",
    "\n",
    "#     return generated_text\n",
    "\n",
    "# generate_with_gpt2(\"Once upon a time,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Intuition\n",
    "# generate_with_gpt2(\"Examples of building structure components for services of plumbing and rain water drainage are\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_with_gpt2_for_astm(level1, level2, level3):\n",
    "#     prompt = f\"Examples of building structure components for {level1.lower()} of {level2.lower()} and {level3.lower()} are\"\n",
    "#     return level1 + \" \" + level2 + \" \" + level3 + \" \" + repr(generate_with_gpt2(prompt)[len(prompt):])\n",
    "\n",
    "# generate_with_gpt2_for_astm(\"SERVICES\", \"Plumbing\", \"Rain Water Drainage\")  # D2040 in ASTM Uniformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # astm_texts = df_astm.apply(\n",
    "# #     lambda row: f\"[pred] {generate_with_gpt2_for_astm(row['Level1'], row['Level2'], row['Level3'])} [succ]\",\n",
    "# #     axis=1\n",
    "# # )\n",
    "\n",
    "\n",
    "# # # Test # TODO: delete\n",
    "# astm_texts = pd.concat([\n",
    "#     pd.Series(100*[\"CONSTRUCTION SUPERSTRUCTURE > Roof > Set Mechanical Equipment [pred] CONSTRUCTION SUPERSTRUCTURE > Roof > Pipe Mechanical Equipment [succ]  100 KINGSHIGHWAY > COMMISSIONNG & INSPECTIONS > STARTUP\"]),\n",
    "#     pd.Series(100*[\"Garage Garage Structure | MEP FP | Finishes > LL1 > OH Sprinkler Piping Rough In LL1 [pred] Garage Garage Structure | MEP FP | Finishes > LL1 > OH Storm Drainage Piping Rough In LL1 [succ] Garage Garage Structure | MEP FP | Finishes > LL1 > Install Pipe Guards | Bollards LL1\"]),\n",
    "# ])\n",
    "# astm_labels = pd.Series([\"[D2040]\"]*200)\n",
    "\n",
    "# for i in range(5):\n",
    "#     print(astm_texts[i], '...', astm_labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### â˜… Additional DataLoader from ASTM Uniformat class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# astm_loader = make_dataloader(astm_texts.tolist(), label_encoder.transform(astm_labels.tolist()), batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import ConcatDataset\n",
    "\n",
    "# merged_dataset = ConcatDataset([train_dataset, astm_dataset])\n",
    "# merged_dataset = ConcatDataset([train_dataset, validation_dataset, test_dataset]) # For testing\n",
    "# merged_loader = DataLoader(merged_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# train_loader = merged_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 1.5e-05\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### â˜… Additional fine-tuning with publicly available ASTM Uniformat II classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# losses = []\n",
    "# for epoch in tqdm(range(200)):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     for input_ids, attention_mask, labels in astm_loader:\n",
    "#         model.zero_grad()\n",
    "#         outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "#         loss = outputs.loss\n",
    "#         total_loss += loss.item()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     losses.append(total_loss / len(astm_loader))\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(losses)\n",
    "# plt.title('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning (Train & Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 640/640 [02:11<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 1.7982293508481235 | Validation Loss: 0.5864716092838305\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(epoch_size):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for input_ids, attention_mask, labels in tqdm(train_loader):\n",
    "        model.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for input_ids, attention_mask, labels in validation_loader:\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            val_loss += loss.item()\n",
    "    val_losses.append(val_loss / len(validation_loader))\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {train_losses[-1]} | Validation Loss: {val_losses[-1]}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    df_test_rows = []\n",
    "    for input_ids, attention_mask, labels in test_loader:\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pred_labels.extend(torch.argmax(outputs.logits, dim=1).cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        for b in range(input_ids.shape[0]):\n",
    "            text = tokenizer.decode([token for i, token in enumerate(input_ids[b]) if attention_mask[b][i] == 1])\n",
    "            pred_label = label_encoder.classes_[torch.argmax(outputs.logits[b]).item()]\n",
    "            true_label = label_encoder.classes_[labels[b].item()]\n",
    "            df_test_rows.append({'text': text, 'true_label': true_label, 'pred_label': pred_label, 'correct': pred_label == true_label})\n",
    "\n",
    "# Data should not be shared publicly.\n",
    "pd.DataFrame(df_test_rows).to_csv(dataset_path+f\"/test_results_{experiment_name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8992\n",
      "Precision: 0.5523\n",
      "Recall: 0.5283\n",
      "F1 Score: 0.5192\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "accuracy = accuracy_score(true_labels, pred_labels)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    true_labels, \n",
    "    pred_labels, \n",
    "    # average='weighted', \n",
    "    average='macro',  # Original paper setting (page 8)\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class-wise Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[A1010]</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.759036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[A1020]</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.845528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[A1030]</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>0.647887</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[A2010]</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.818898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[A2020]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[B1010]</td>\n",
       "      <td>0.976631</td>\n",
       "      <td>0.996028</td>\n",
       "      <td>0.986234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[B1020]</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.946565</td>\n",
       "      <td>0.767802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[B2010]</td>\n",
       "      <td>0.966312</td>\n",
       "      <td>0.985533</td>\n",
       "      <td>0.975828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[B2020]</td>\n",
       "      <td>0.987879</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[B2030]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[B3010]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[B3020]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[C1010]</td>\n",
       "      <td>0.911304</td>\n",
       "      <td>0.986817</td>\n",
       "      <td>0.947559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[C1020]</td>\n",
       "      <td>0.820690</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.898113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[C1030]</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.758621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[C2010]</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[C2020]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[C3010]</td>\n",
       "      <td>0.975155</td>\n",
       "      <td>0.978193</td>\n",
       "      <td>0.976672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[C3020]</td>\n",
       "      <td>0.897033</td>\n",
       "      <td>0.980916</td>\n",
       "      <td>0.937101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[C3030]</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.985836</td>\n",
       "      <td>0.970711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[D1010]</td>\n",
       "      <td>0.958115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[D1020]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[D1090]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[D2010]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>0.274510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[D2020]</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.982301</td>\n",
       "      <td>0.917355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[D2030]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[D2040]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[D2090]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[D3010]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[D3020]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[D3030]</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.821429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[D3040]</td>\n",
       "      <td>0.807143</td>\n",
       "      <td>0.914980</td>\n",
       "      <td>0.857685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[D3050]</td>\n",
       "      <td>0.966006</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.952514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[D3060]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[D3070]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[D4010]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[D4020]</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.949640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[D4030]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[D4090]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[D5010]</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.715686</td>\n",
       "      <td>0.768421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[D5020]</td>\n",
       "      <td>0.852349</td>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.888112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[D5030]</td>\n",
       "      <td>0.592417</td>\n",
       "      <td>0.954198</td>\n",
       "      <td>0.730994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[D5090]</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>0.149533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[E1010]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[E1020]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[E1030]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[E1090]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.682927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[E2010]</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.755102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[E2020]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class  Precision    Recall  F1 Score\n",
       "0   [A1010]   0.636364  0.940299  0.759036\n",
       "1   [A1020]   0.838710  0.852459  0.845528\n",
       "2   [A1030]   0.836364  0.647887  0.730159\n",
       "3   [A2010]   0.981132  0.702703  0.818898\n",
       "4   [A2020]   0.000000  0.000000  0.000000\n",
       "5   [B1010]   0.976631  0.996028  0.986234\n",
       "6   [B1020]   0.645833  0.946565  0.767802\n",
       "7   [B2010]   0.966312  0.985533  0.975828\n",
       "8   [B2020]   0.987879  1.000000  0.993902\n",
       "9   [B2030]   0.000000  0.000000  0.000000\n",
       "10  [B3010]   0.000000  0.000000  0.000000\n",
       "11  [B3020]   0.000000  0.000000  0.000000\n",
       "12  [C1010]   0.911304  0.986817  0.947559\n",
       "13  [C1020]   0.820690  0.991667  0.898113\n",
       "14  [C1030]   0.721311  0.800000  0.758621\n",
       "15  [C2010]   0.977273  0.524390  0.682540\n",
       "16  [C2020]   0.000000  0.000000  0.000000\n",
       "17  [C3010]   0.975155  0.978193  0.976672\n",
       "18  [C3020]   0.897033  0.980916  0.937101\n",
       "19  [C3030]   0.956044  0.985836  0.970711\n",
       "20  [D1010]   0.958115  1.000000  0.978610\n",
       "21  [D1020]   1.000000  1.000000  1.000000\n",
       "22  [D1090]   1.000000  0.500000  0.666667\n",
       "23  [D2010]   1.000000  0.159091  0.274510\n",
       "24  [D2020]   0.860465  0.982301  0.917355\n",
       "25  [D2030]   0.000000  0.000000  0.000000\n",
       "26  [D2040]   0.000000  0.000000  0.000000\n",
       "27  [D2090]   0.000000  0.000000  0.000000\n",
       "28  [D3010]   0.000000  0.000000  0.000000\n",
       "29  [D3020]   0.000000  0.000000  0.000000\n",
       "30  [D3030]   0.704082  0.985714  0.821429\n",
       "31  [D3040]   0.807143  0.914980  0.857685\n",
       "32  [D3050]   0.966006  0.939394  0.952514\n",
       "33  [D3060]   0.000000  0.000000  0.000000\n",
       "34  [D3070]   0.000000  0.000000  0.000000\n",
       "35  [D4010]   1.000000  1.000000  1.000000\n",
       "36  [D4020]   0.916667  0.985075  0.949640\n",
       "37  [D4030]   0.000000  0.000000  0.000000\n",
       "38  [D4090]   0.000000  0.000000  0.000000\n",
       "39  [D5010]   0.829545  0.715686  0.768421\n",
       "40  [D5020]   0.852349  0.927007  0.888112\n",
       "41  [D5030]   0.592417  0.954198  0.730994\n",
       "42  [D5090]   0.800000  0.082474  0.149533\n",
       "43  [E1010]   0.000000  0.000000  0.000000\n",
       "44  [E1020]   0.000000  0.000000  0.000000\n",
       "45  [E1030]   0.000000  0.000000  0.000000\n",
       "46  [E1090]   1.000000  0.518519  0.682927\n",
       "47  [E2010]   0.649123  0.902439  0.755102\n",
       "48  [E2020]   0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average=None, zero_division=0)\n",
    "\n",
    "class_names = label_encoder.inverse_transform(list(set(true_labels)))\n",
    "\n",
    "performance_df = pd.DataFrame({\n",
    "    'Class': class_names,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1\n",
    "})\n",
    "performance_df.to_csv(f'experimental_results_rseed{rseed}_{experiment_name}.csv')\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
